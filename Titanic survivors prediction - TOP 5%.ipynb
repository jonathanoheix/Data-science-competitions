{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6615d6ae3849cea80c5d3736960e559754781ec"
   },
   "source": [
    "# Titanic: Machine Learning from disaster\n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "## Competition Description\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "## Goal\n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not. \n",
    "For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n",
    "\n",
    "## Metric\n",
    "Your score is the percentage of passengers you correctly predict. This is known simply as \"accuracy‚Äù.\n",
    "\n",
    "## Submission File Format\n",
    "You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "PassengerId (sorted in any order)\n",
    "Survived (contains your binary predictions: 1 for survived, 0 for deceased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c260218e84253e55673b6d7ec85c614555ef9034"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9293872eef4c3f682553dbae72754cc8e7dc07d"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "79604b2468f7e819b394fe4e497ffe8dc588a85b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n",
       "0            1         0       3    ...      7.2500   NaN         S\n",
       "1            2         1       1    ...     71.2833   C85         C\n",
       "2            3         1       3    ...      7.9250   NaN         S\n",
       "3            4         1       1    ...     53.1000  C123         S\n",
       "4            5         0       3    ...      8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "d048beca048c2b52393903a5bc181a6490147586"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "# append the two datasets for feature engineering\n",
    "train_df[\"dataset\"] = \"train\"\n",
    "pred_df[\"dataset\"] = \"pred\"\n",
    "data_df = train_df.append(pred_df, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "e566caeb7da335d96b951561a8294810eb271a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             263\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Fare              1\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived        418\n",
       "Ticket            0\n",
       "dataset           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show missing values\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96be088119ddd9eabc982eb7147579fba30be8e9"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28789e718054a2ec81c1b64c72c9d100e45997ce"
   },
   "source": [
    "The 'Name' column contains interesting information: the family name and the title. The title can give us relevant information about the marital status and age. The family name can help us to find if some persons of the individual's family survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "85b6b56af77364a34bb339877193ae2649dd2c70"
   },
   "outputs": [],
   "source": [
    "# clean name and extracting Title\n",
    "\n",
    "data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "\n",
    "# replace rare titles with more common ones\n",
    "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "\n",
    "data_df.replace({'Title': mapping}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd54dd30f6b22a3fdedb11556f8dab3ebad21787"
   },
   "source": [
    "A lot of age values are missing. We can impute the using the median of the persons with the same title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "fe09b8b9e10c96e7acfe3eb6419082de86fc727c"
   },
   "outputs": [],
   "source": [
    "titles = list(data_df.Title.value_counts().index)\n",
    "\n",
    "# for each title, impute missing age by the median of the persons with the same title\n",
    "for title in titles:\n",
    "    age_to_impute = data_df.groupby('Title')['Age'].median()[title]\n",
    "    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa6c107e606c9cd9f4de79c5f0e4f92f525bf67f"
   },
   "source": [
    "The Parch variable corresponds to the number of parents or children aboard the Titanic. The SibSp variable corresponds to the number of siblings or spouses aboard the Titanic. We can add those two variables in order to get the size of the family that was onboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "f1d26db79c5da480e36f519e19b9e6d1bb6f66ac"
   },
   "outputs": [],
   "source": [
    "# compute family size\n",
    "data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89403188681f96a49ae8853507150e327f7da6fa"
   },
   "source": [
    "Now we can try to retrieve information about family survival.\n",
    "There are two ways to find people from the same family:\n",
    "- they have the same last name and they paid the same family fare\n",
    "- they have the same ticket id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "286fe46433f39a2f176c8025de4eef299368b9ff"
   },
   "outputs": [],
   "source": [
    "# get the last name (family name): the string part before the ,\n",
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "# remove null fare values\n",
    "data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "52b62317017efa8056d7ef01fdded8006d627cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n"
     ]
    }
   ],
   "source": [
    "# get information about family survival using Last_Name and Fare\n",
    "\n",
    "# 0.5: default value for no information\n",
    "# 1: someone of the same family survived\n",
    "# 0: we don't know if somebody survived but we know that somebody died\n",
    "\n",
    "default_survival_value = 0.5\n",
    "data_df['Family_Survival'] = default_survival_value\n",
    "\n",
    "for grp, grp_df in data_df.groupby(['Last_Name', 'Fare']):\n",
    "    # if a family group is found\n",
    "    if (len(grp_df) != 1):\n",
    "        # for every person, look for the other people from the same family\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            \n",
    "            if (smax == 1.0): # if anyone in the family survived, assign 1\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0): # else if we saw someone dead, assign 0\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "5b5a94297357af97770ed4d0ab1d248a780c6a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passenger with family survival information: 546\n"
     ]
    }
   ],
   "source": [
    "# get information about family survival using the Ticket number\n",
    "\n",
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    # if a family group is found\n",
    "    if (len(grp_df) != 1):\n",
    "        # for every person, look for the other people from the same family\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0): # if anyone in the family survived, assign 1\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0): # else if we saw someone dead, assign 0\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "print(\"Number of passenger with family survival information: \" \n",
    "      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f372e400af62ab73d16e8db282a00daccdd61d68"
   },
   "source": [
    "Next we regroup Fare and Age into bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "fe42d9d6a87f58a3ac83ca7b82494a434402c659"
   },
   "outputs": [],
   "source": [
    "# fare bins\n",
    "data_df['FareBin'] = pd.qcut(data_df['Fare'], 5)\n",
    "label = LabelEncoder()\n",
    "data_df['FareBin_Code'] = label.fit_transform(data_df['FareBin'])\n",
    "data_df.drop(['Fare'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "21fa2a423dfb49b286691a60f729a06e9714fa5d"
   },
   "outputs": [],
   "source": [
    "# age bins\n",
    "data_df['AgeBin'] = pd.qcut(data_df['Age'], 4)\n",
    "label = LabelEncoder()\n",
    "data_df['AgeBin_Code'] = label.fit_transform(data_df['AgeBin'])\n",
    "data_df.drop(['Age'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "10c7073b7c69bd89686c9cd4e4ebb5f47d9d111c"
   },
   "outputs": [],
   "source": [
    "# encode sex variable\n",
    "data_df['Sex'].replace(['male','female'],[0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "52eee0b1b6cc2182c13349dc713dac3451ba2b96"
   },
   "outputs": [],
   "source": [
    "# choose features and labels\n",
    "label = \"Survived\"\n",
    "features = [\"Pclass\", \"Sex\", \"Family_Size\", \"Family_Survival\", \"FareBin_Code\", \"AgeBin_Code\"]\n",
    "\n",
    "# split back data_df into train and prediction sets\n",
    "train_df = data_df[data_df[\"dataset\"] == \"train\"][features + [label]]\n",
    "pred_df = data_df[data_df[\"dataset\"] == \"pred\"][features]\n",
    "\n",
    "# convert Survived variable to int for train dataset\n",
    "train_df[\"Survived\"] = train_df[\"Survived\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "240cc12fa344c4c934dd0523983170882ff0e7ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Family_Size    ...     FareBin_Code  AgeBin_Code  Survived\n",
       "0       3    0            1    ...                0            0         0\n",
       "1       1    1            1    ...                4            3         1\n",
       "2       3    1            0    ...                1            1         1\n",
       "3       1    1            1    ...                4            2         1\n",
       "4       3    0            0    ...                1            2         0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fba24be5599786a5cf93f6452d791d66828b393"
   },
   "source": [
    "# Train and test KNN classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "c6e31e4e1dc1c352465a4bd815ee247afb5855b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# setup dataframes\n",
    "X = train_df[features]\n",
    "y = train_df['Survived']\n",
    "X_pred = pred_df\n",
    "\n",
    "# scale data for KNN classifier\n",
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_pred = std_scaler.transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "048fc9020024bb77b8d8d9ce901998f8f4738d5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "0.879492358564122\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=18, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2400 out of 2400 | elapsed:   36.2s finished\n"
     ]
    }
   ],
   "source": [
    "# setup parameters values for grid search\n",
    "n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'weights': weights, 'leaf_size': leaf_size, 'n_neighbors': n_neighbors}\n",
    "\n",
    "\n",
    "gd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\")\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "525d71d68a9d9e9b33f774cf0130a547dd5b91ec"
   },
   "source": [
    "# Submit predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "768c80cdd2b8d1c018c42d2abea3a441a5d85e60"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(X_pred)\n",
    "\n",
    "# output predictions dataframe\n",
    "temp = pd.DataFrame(pd.read_csv(\"../input/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = y_pred\n",
    "temp.to_csv(\"../working/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6d93a9a39ecbc4787f0f5787d1cc562fcae28a9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
